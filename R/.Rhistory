old_lambda <- new_lambda
}
# Break condition
if(w_iter <= 2){
# Calculate the latest R
y <- apply(xmat,1,t_to_y,w=new_w)
x = c()
for(n in 1:N){
x[n] <- y[n]*(1-y[n])
}
R <- diag(x)
# Calculate w_sd
S_n <- solve(new_lambda * diag(M) + t(xmat) %*% R %*% xmat)
w_sd <- sqrt(diag(S_n))
break;
}
}
lambda_new
new_lambda
w_sd
# Default if not provided
lambda_rate <- 0.0005
param_tol <- 0.00001
granditertol <- 2
outitermax <- 50
inneritermax <- 20
debuglevel <- 0
N <- length(dm_train_t)
M <- ncol(xmat)
# Initial lambda
init_lambda <- lambda_rate * N
old_lambda <- init_lambda
# Initial w
init_w <- as.vector(unname(solve(init_lambda * diag(M) + t(xmat) %*% xmat) %*% t(xmat) %*% t))
old_w <- init_w
# Function to calculate y
t_to_y <- function(row,w){
return(1 / (1 + exp(-(t(w) %*% row))))
}
# BEGINNING OF FOR LOOP
for(i in 1:outitermax){
w_iter <- 0
for( j in 1:inneritermax){
# Increment number of inner loop iterations
w_iter <- w_iter + 1
# Calculate new y with w
y <- apply(xmat,1,t_to_y,w=old_w)
# Calculate R - REMEMBER TO UPDATE
x = c()
for(n in 1:N){
x[n] <- y[n]*(1-y[n])
}
R <- diag(x)
# Calculate Gradient
grad <- old_lambda * old_w + t(xmat)%*%(y-t)
# Calculate Hessian
hess <- t(xmat) %*% R %*% xmat + old_lambda * diag(M)
# Calculate new w
new_w <- as.vector(old_w - (solve(hess) %*% (old_lambda * old_w + t(xmat) %*% (y-t))))
# Calculate MAD
MAD <- 0
for(n in 1:length(old_w)){
MAD <- MAD + abs(old_w[n]-new_w[n])
}
MAD <- MAD / length(old_w)
# Update w
old_w <- new_w
# Break if MAD is less than threshhold
if(MAD < param_tol) break
}
for( k in 1:inneritermax){
# Calculate gamma
eigenvalue <- eigen((t(xmat)%*%R%*%xmat), FALSE, only.values = TRUE, EISPACK = FALSE)
gamma <- 0
for(i in 1:length(eigenvalue$values)){
gamma <- gamma + eigenvalue$values[i]/(old_lambda + eigenvalue$values[i])
}
# Calculate new lambda
new_lambda <- as.numeric(gamma / (t(new_w) %*% new_w))
# Break if MAD is less than threshhold
if(abs(old_lambda - new_lambda) < param_tol){
old_lambda <- new_lambda
break
}
old_lambda <- new_lambda
}
# Break condition
if(w_iter <= 2){
# Calculate the latest R
y <- apply(xmat,1,t_to_y,w=new_w)
x = c()
for(n in 1:N){
x[n] <- y[n]*(1-y[n])
}
R <- diag(x)
# Calculate w_sd
S_n <- solve(new_lambda * diag(M) + t(xmat) %*% R %*% xmat)
w_sd <- sqrt(diag(S_n))
break;
}
}
str(xmat)
str(as.matrix(xmat))
# Default if not provided
lambda_rate <- 0.0005
param_tol <- 0.00001
granditertol <- 2
outitermax <- 50
inneritermax <- 20
debuglevel <- 0
N <- length(dm_train_t)
M <- ncol(xmat)
t <- y
# Initial lambda
init_lambda <- lambda_rate * N
old_lambda <- init_lambda
# Initial w
init_w <- solve(init_lambda * diag(M) + t(xmat) %*% xmat) %*% t(xmat) %*% t
old_w <- init_w
# Function to calculate y
t_to_y <- function(row,w){
return(1 / (1 + exp(-(t(w) %*% row))))
}
# BEGINNING OF FOR LOOP
for(i in 1:outitermax){
w_iter <- 0
for( j in 1:inneritermax){
# Increment number of inner loop iterations
w_iter <- w_iter + 1
# Calculate new y with w
y <- as.matrix(apply(xmat,1,t_to_y,w=old_w))
# Calculate R - REMEMBER TO UPDATE
x = c()
for(n in 1:N){
x[n] <- y[n]*(1-y[n])
}
R <- diag(x)
# Calculate Gradient
grad <- old_lambda * old_w + t(xmat)%*%(y-t)
# Calculate Hessian
hess <- t(xmat) %*% R %*% xmat + old_lambda * diag(M)
# Calculate new w
new_w <- as.vector(old_w - (solve(hess) %*% (old_lambda * old_w + t(xmat) %*% (y-t))))
# Calculate MAD
MAD <- 0
for(n in 1:length(old_w)){
MAD <- MAD + abs(old_w[n]-new_w[n])
}
MAD <- MAD / length(old_w)
# Update w
old_w <- new_w
# Break if MAD is less than threshhold
if(MAD < param_tol) break
}
for( k in 1:inneritermax){
# Calculate the latest R
y <- apply(xmat,1,t_to_y,w=new_w)
x = c()
for(n in 1:N){
x[n] <- y[n]*(1-y[n])
}
R <- diag(x)
# Calculate gamma
eigenvalue <- eigen((t(xmat)%*%R%*%xmat), FALSE, only.values = TRUE, EISPACK = FALSE)
gamma <- 0
for(i in 1:length(eigenvalue$values)){
gamma <- gamma + eigenvalue$values[i]/(old_lambda + eigenvalue$values[i])
}
# Calculate new lambda
new_lambda <- as.numeric(gamma / (t(new_w) %*% new_w))
# Break if MAD is less than threshhold
if(abs(old_lambda - new_lambda) < param_tol){
old_lambda <- new_lambda
break
}
old_lambda <- new_lambda
}
# Break condition
if(w_iter <= 2){
# Calculate w_sd
S_n <- solve(new_lambda * diag(M) + t(xmat) %*% R %*% xmat)
w_sd <- sqrt(diag(S_n))
# Set up answer
ans <- list(w = new_w, w_sd = w_sd, lambda = new_lambda, M = M, N = N)
return(ans)
}
}
# Default if not provided
lambda_rate <- 0.0005
param_tol <- 0.00001
granditertol <- 2
outitermax <- 50
inneritermax <- 20
debuglevel <- 0
N <- length(dm_train_t)
M <- ncol(xmat)
t <- y
# Initial lambda
init_lambda <- lambda_rate * N
old_lambda <- init_lambda
# Initial w
init_w <- solve(init_lambda * diag(M) + t(xmat) %*% xmat) %*% t(xmat) %*% t
old_w <- init_w
# Function to calculate y
t_to_y <- function(row,w){
return(1 / (1 + exp(-(t(w) %*% row))))
}
# BEGINNING OF FOR LOOP
for(i in 1:outitermax){
w_iter <- 0
for( j in 1:inneritermax){
# Increment number of inner loop iterations
w_iter <- w_iter + 1
# Calculate new y with w
y <- as.matrix(apply(xmat,1,t_to_y,w=old_w))
# Calculate R - REMEMBER TO UPDATE
x = c()
for(n in 1:N){
x[n] <- y[n]*(1-y[n])
}
R <- diag(x)
# Calculate Gradient
grad <- old_lambda * old_w + t(xmat)%*%(y-t)
# Calculate Hessian
hess <- t(xmat) %*% R %*% xmat + old_lambda * diag(M)
# Calculate new w
new_w <- as.vector(old_w - (solve(hess) %*% (old_lambda * old_w + t(xmat) %*% (y-t))))
# Calculate MAD
MAD <- 0
for(n in 1:length(old_w)){
MAD <- MAD + abs(old_w[n]-new_w[n])
}
MAD <- MAD / length(old_w)
# Update w
old_w <- new_w
# Break if MAD is less than threshhold
if(MAD < param_tol) break
}
for( k in 1:inneritermax){
# Calculate the latest R
y <- apply(xmat,1,t_to_y,w=new_w)
x = c()
for(n in 1:N){
x[n] <- y[n]*(1-y[n])
}
R <- diag(x)
# Calculate gamma
eigenvalue <- eigen((t(xmat)%*%R%*%xmat), FALSE, only.values = TRUE, EISPACK = FALSE)
gamma <- 0
for(i in 1:length(eigenvalue$values)){
gamma <- gamma + eigenvalue$values[i]/(old_lambda + eigenvalue$values[i])
}
# Calculate new lambda
new_lambda <- as.numeric(gamma / (t(new_w) %*% new_w))
# Break if MAD is less than threshhold
if(abs(old_lambda - new_lambda) < param_tol){
old_lambda <- new_lambda
break
}
old_lambda <- new_lambda
}
# Break condition
if(w_iter <= 2){
# Calculate w_sd
S_n <- solve(new_lambda * diag(M) + t(xmat) %*% R %*% xmat)
w_sd <- sqrt(diag(S_n))
# Set up answer
ans <- list(w = new_w, w_sd = w_sd, lambda = new_lambda, M = M, N = N)
}
}
ans
w_old
new_w
logicreg_l2_train <- function(y, xmat, lambda_rate = 0.0005, param_tol = 10^(-5), granditertol = 2, outitermax = 50, inneritermax = 20, debuglevel = 0){
N <- length(dm_train_t)
M <- ncol(xmat)
t <- y
# Initial lambda
init_lambda <- lambda_rate * N
old_lambda <- init_lambda
# Initial w
init_w <- solve(init_lambda * diag(M) + t(xmat) %*% xmat) %*% t(xmat) %*% t
old_w <- init_w
# Function to calculate y
t_to_y <- function(row,w){
return(1 / (1 + exp(-(t(w) %*% row))))
}
# BEGINNING OF FOR LOOP
for(i in 1:outitermax){
w_iter <- 0
for( j in 1:inneritermax){
# Increment number of inner loop iterations
w_iter <- w_iter + 1
# Calculate new y with w
y <- as.matrix(apply(xmat,1,t_to_y,w=old_w))
# Calculate R - REMEMBER TO UPDATE
x = c()
for(n in 1:N){
x[n] <- y[n]*(1-y[n])
}
R <- diag(x)
# Calculate Gradient
grad <- old_lambda * old_w + t(xmat)%*%(y-t)
# Calculate Hessian
hess <- t(xmat) %*% R %*% xmat + old_lambda * diag(M)
# Calculate new w
new_w <- as.vector(old_w - (solve(hess) %*% (old_lambda * old_w + t(xmat) %*% (y-t))))
# Calculate MAD
MAD <- 0
for(n in 1:length(old_w)){
MAD <- MAD + abs(old_w[n]-new_w[n])
}
MAD <- MAD / length(old_w)
# Update w
old_w <- new_w
# Break if MAD is less than threshhold
if(MAD < param_tol) break
}
for( k in 1:inneritermax){
# Calculate the latest R
y <- apply(xmat,1,t_to_y,w=new_w)
x = c()
for(n in 1:N){
x[n] <- y[n]*(1-y[n])
}
R <- diag(x)
# Calculate gamma
eigenvalue <- eigen((t(xmat)%*%R%*%xmat), FALSE, only.values = TRUE, EISPACK = FALSE)
gamma <- 0
for(i in 1:length(eigenvalue$values)){
gamma <- gamma + eigenvalue$values[i]/(old_lambda + eigenvalue$values[i])
}
# Calculate new lambda
new_lambda <- as.numeric(gamma / (t(new_w) %*% new_w))
# Break if MAD is less than threshhold
if(abs(old_lambda - new_lambda) < param_tol){
old_lambda <- new_lambda
break
}
old_lambda <- new_lambda
}
# Break condition
if(w_iter <= 2){
# Calculate w_sd
S_n <- solve(new_lambda * diag(M) + t(xmat) %*% R %*% xmat)
w_sd <- sqrt(diag(S_n))
# Set up answer
ans <- list(w = new_w, w_sd = w_sd, lambda = new_lambda, M = M, N = N)
return(ans)
}
}
}
dm_train_t <- as.numeric(ds4a_train[,1] == "pos")
t <- as.matrix(dm_train_t)
xmat <- model.matrix(~f_past+g1+g2+g3+g4+g5+g6+g7+g8+g9+g10,data=ds4a_train[,-1])
model1 <- logicreg_l2_train(tall, xmat, debuglevel=0)
model1 <- logicreg_l2_train(t, xmat, debuglevel=0)
new_w[1]
tall <- as.matrix(dm_train_t)
model1 <- logicreg_l2_train(tall, xmat, debuglevel=0)
model1
new_w[1]
xmattest1 <- model.matrix(~f_past+g1+g2+g3+g4+g5+g6+g7+g8+g9+g10,data=ds4a_train[,-1])
head(xmattest1)
for(i in 1:nrow(xmattest1)){
sum <- 0
for(j in 1:ncol(xmattest1)){
sum = sum + w_new[j] * xmattest1[i][j]
}
prob[i] <- sum
}
sum = sum + new_w[j] * xmattest1[i][j]
### Q2b
prob <- c()
class <- c()
xmattest1 <- model.matrix(~f_past+g1+g2+g3+g4+g5+g6+g7+g8+g9+g10,data=ds4a_train[,-1])
head(xmattest1)
for(i in 1:nrow(xmattest1)){
sum <- 0
for(j in 1:ncol(xmattest1)){
sum = sum + new_w[j] * xmattest1[i][j]
}
prob[i] <- sum
}
prob
head(new_w)
xmattest1[1:5,1:12]
for(i in 1:nrow(xmattest1)){
sum <- 0
for(j in 1:ncol(xmattest1)){
sum = sum + new_w[j] * xmattest1[i,j]
}
prob[i] <- sum
}
prob
for(i in 1:nrow(xmattest1)){
sum <- new_w[1]
for(j in 2:ncol(xmattest1)){
sum = sum + new_w[j] * xmattest1[i,j]
}
prob[i] <- sum
}
prob
xmattest1[1:5,1:12]
prob
for(i in 1:nrow(xmattest1)){
for(j in 1:ncol(xmattest1)){
sum = sum + new_w[j] * xmattest1[i,j]
}
prob[i] <- sum
}
prob
for(i in 1:nrow(xmattest1)){
sum <- 0
for(j in 1:ncol(xmattest1)){
sum = sum + new_w[j] * xmattest1[i,j]
}
prob[i] <- sum
}
prob
t_to_y <- function(row,w){
return(1 / (1 + exp(-(t(w) %*% row))))
}
y <- as.matrix(apply(xmattest1,1,t_to_y,w=new_w))
y
model1
model1$w
model1$
t_to_y <- function(row,w){
return(1 / (1 + exp(-(t(w) %*% row))))
}
model1
model1$w
t_to_y <- function(row,w){
return(1 / (1 + exp(-(t(w) %*% row))))
}
y <- as.matrix(apply(xmattest1,1,t_to_y,w=model1$w))
y
for(i in 1:nrow(xmattest1)){
if(y[i] > 0.5){
class[i] = 1
}
else
class[i] = 0
}
class
### Q2b
prob <- c()
class <- c()
xmattest1 <- model.matrix(~f_past+g1+g2+g3+g4+g5+g6+g7+g8+g9+g10,data=ds4a_train[,-1])
head(xmattest1)
model1
t_to_y <- function(row,w){
return(1 / (1 + exp(-(t(w) %*% row))))
}
y <- as.matrix(apply(xmattest1,1,t_to_y,w=model1$w))
y
for(i in 1:nrow(xmattest1)){
if(y[i] > 0.5){
class[i] = 1
}
else
class[i] = 0
}
class
### Q2b
prob <- c()
class <- c()
xmattest1 <- model.matrix(~f_past+g1+g2+g3+g4+g5+g6+g7+g8+g9+g10,data=ds4a_train[,-1])
head(xmattest1)
model1
t_to_y <- function(row,w){
return(1 / (1 + exp(-(t(w) %*% row))))
}
y <- as.matrix(apply(xmattest1,1,t_to_y,w=model1$w))
y
y
t_to_y <- function(row,w){
return(1 / (1 + exp(-(t(w) %*% row))))
}
logicreg_l2_predict() <- function(model1, xmattest1){
prob <- as.matrix(apply(xmattest1,1,t_to_y,w=model1$w))
}
logicreg_l2_predict() <- function(model1, xmattest1){
prob <- as.matrix(apply(xmattest1,1,t_to_y,w=model1$w))
class <- c()
for(i in 1:nrow(xmattest1)){
if(y[i] > 0.5){
class[i] = 1
}
else
class[i] = 0
}
ans <- list(prob = prob, class=class)
return(ans)
}
logicreg_l2_predict <- function(model1, xmattest1){
prob <- as.matrix(apply(xmattest1,1,t_to_y,w=model1$w))
class <- c()
for(i in 1:nrow(xmattest1)){
if(y[i] > 0.5){
class[i] = 1
}
else
class[i] = 0
}
ans <- list(prob = prob, class=class)
return(ans)
}
logicpred1 <- logicreg_l2_predict(model1, xmattest1)
head(logicpred1$class,n=25)
head(logicpred1$prob,n=25)
